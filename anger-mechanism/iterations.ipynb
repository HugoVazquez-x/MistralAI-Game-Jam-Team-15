{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining the \"best\" French cheese can be quite subjective, as it depends on personal taste. France is renowned for its wide variety of cheeses, with over 1,000 different types. Here are a few highly regarded French cheeses across various categories:\n",
      "\n",
      "1. **Soft Cheeses**:\n",
      "   - **Brie de Meaux**: Often referred to as the \"King of Cheeses,\" it is known for its rich, creamy interior and delicate taste.\n",
      "   - **Camembert de Normandie**: Another famous soft cheese with a smooth, creamy interior and a white bloomy rind.\n",
      "\n",
      "2. **Semi-Soft Cheeses**:\n",
      "   - **Reblochon**: A savory cheese from the Alps with a nutty flavor and a soft, washed rind.\n",
      "   - **Munster**: A strong-tasting cheese with a washed rind, typically from the Vosges region.\n",
      "\n",
      "3. **Hard Cheeses**:\n",
      "   - **Comté**: A popular hard cheese made from unpasteurized cow’s milk, known for its complex flavors that range from sweet to nutty.\n",
      "   - **Beaufort**: A firm, raw cow's milk cheese with a slightly grainy texture and a rich, nutty flavor.\n",
      "\n",
      "4. **Blue Cheeses**:\n",
      "   - **Roquefort**: A famous blue cheese made from sheep milk, known for its strong, tangy flavor and crumbly texture.\n",
      "   - **Bleu d'Auvergne**: A milder blue cheese with a creamy texture and a delicate flavor.\n",
      "\n",
      "5. **Goat Cheeses**:\n",
      "   - **Sainte-Maure de Touraine**: A log-shaped goat cheese with a distinctive taste and a slight tang.\n",
      "   - **Crottin de Chavignol**: A small, cylindrical goat cheese with a firm texture and a range of flavors from mild to strong.\n",
      "\n",
      "Each of these cheeses has its own unique characteristics and is beloved for different reasons. The best way to find your favorite is to try a variety and see which ones you enjoy the most!\n"
     ]
    }
   ],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "MISTRAL_KEY = \"MaFKaY7R8TYrOLd56ZDRBcUfatOrebRh\"\n",
    "\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "# Initialize the Mistral client\n",
    "client = Mistral(api_key=MISTRAL_KEY)\n",
    "\n",
    "# Create a chat completion\n",
    "chat_response = client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the best French cheese?\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the assistant's response\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "MODEL = \"ministral-8b-latest\"\n",
    "\n",
    "def link_with_newline_middle(strings):\n",
    "    if len(strings) <= 1:\n",
    "        return ''.join(strings)  # Return as is for single or empty lists\n",
    "    middle = len(strings) // 2\n",
    "    # Join the first part, add '\\n', and then join the rest\n",
    "    return '\\n'.join([' '.join(strings[:middle]), ' '.join(strings[middle:])])\n",
    "\n",
    "\n",
    "class AIAgent:\n",
    "    def __init__(self, name, character, emotions, goal, general_context, arbitrary_agent):\n",
    "        \"\"\"\n",
    "        Initialise l'agent IA avec ses attributs de base.\n",
    "\n",
    "        :param character: Dictionnaire décrivant la personnalité de l'IA (par ex. calme, agressif, analytique).\n",
    "        :param emotions: Dictionnaire des émotions actuelles de l'IA.\n",
    "        :param environment: Dictionnaire décrivant l'état actuel de l'environnement.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.character = character\n",
    "        self.emotions = emotions\n",
    "        self.goal = goal\n",
    "        self.general_context = general_context\n",
    "        self.arbitrary_agent = arbitrary_agent\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def respond(self, input_text, opponent_state):\n",
    "        \"\"\"\n",
    "        Génère une réponse basée sur le contexte fourni.\n",
    "\n",
    "        :param input_text: Texte reçu de l'utilisateur ou de l'adversaire.\n",
    "        :param opponent_state: Dictionnaire décrivant l'état actuel de l'adversaire.\n",
    "        :return: Réponse de l'agent IA.\n",
    "        \"\"\"\n",
    "        # Ajouter le texte à l'historique de la conversation\n",
    "        self.conversation_history.append({\"user\": input_text})\n",
    "\n",
    "        # Générer une réponse basée sur les différents contextes\n",
    "        response = self._generate_response(input_text, opponent_state)\n",
    "\n",
    "        # Ajouter la réponse de l'IA à l'historique\n",
    "        self.conversation_history.append({self.name: response})\n",
    "\n",
    "        return response\n",
    "\n",
    "    def update_emotions(self, emotions):\n",
    "        arbitrary_agent = self.arbitrary_agent\n",
    "\n",
    "\n",
    "    def _generate_response(self, instructions, opponent_state, environment_description, max_tokens = None):\n",
    "        # Structure the messages list correctly\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    f\"General context: {self.general_context}\\n\"\n",
    "                    f\"Character: {self.character}\\n\"\n",
    "                    f\"Goal: {self.goal}\\n\"\n",
    "                    f\"Emotions: {self.emotions}\\n\"\n",
    "                    f\"Environment: {environment_description}\\n\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"Instructions: {instructions}\\n\"\n",
    "                    f\"Opponent state: {opponent_state}\\n\"\n",
    "                    f\"Conversation history: {self.conversation_history}\"\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # Call the chat completion API\n",
    "        chat_response = client.chat.complete(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "    max_tokens=max_tokens,  # Adjust this value as needed\n",
    ")\n",
    "        \n",
    "        # Extract and return the assistant's response\n",
    "        return chat_response.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General context for the debate\n",
    "general_context = {\n",
    "    \"topic\": \"Economic Policy\",\n",
    "    \"setting\": \"Televised national debate\",\n",
    "    \"audience\": \"Undecided voters seeking clarity on candidates' economic plans\"\n",
    "}\n",
    "\n",
    "# Attributes for Donald Trump\n",
    "trump_character = {\n",
    "    \"dominant\": True,\n",
    "    \"charismatic\": True,\n",
    "    \"unpredictable\": True,\n",
    "    \"assertive\": True,\n",
    "    \"narcissistic\": True\n",
    "}\n",
    "\n",
    "trump_emotions = {\n",
    "    \"confidence\": 0.9,\n",
    "    \"aggressiveness\": 0.8,\n",
    "    \"enthusiasm\": 0.7\n",
    "}\n",
    "\n",
    "trump_goal = \"Persuade the audience that his economic policies will lead to national prosperity and job growth.\"\n",
    "\n",
    "# Attributes for Kamala Harris\n",
    "harris_character = {\n",
    "    \"analytical\": True,\n",
    "    \"empathetic\": True,\n",
    "    \"methodical\": True,\n",
    "    \"decisive\": True,\n",
    "    \"direct\": True\n",
    "}\n",
    "\n",
    "harris_emotions = {\n",
    "    \"confidence\": 0.85,\n",
    "    \"determination\": 0.9,\n",
    "    \"calmness\": 0.8\n",
    "}\n",
    "\n",
    "harris_goal = \"Convince the audience that her economic plans offer sustainable growth and address income inequality.\"\n",
    "\n",
    "# Creating the AI agent instances\n",
    "trump_agent = AIAgent(\n",
    "    name=\"Donald Trump\",\n",
    "    character=trump_character,\n",
    "    emotions=trump_emotions,\n",
    "    goal=trump_goal,\n",
    "    general_context=general_context\n",
    ")\n",
    "\n",
    "harris_agent = AIAgent(\n",
    "    name=\"Kamala Harris\",\n",
    "    character=harris_character,\n",
    "    emotions=harris_emotions,\n",
    "    goal=harris_goal,\n",
    "    general_context=general_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Tour de débat n°1\n",
      "==================================================\n",
      "\n",
      "[MODERATOR] Question: How will your policies affect small businesses?\n",
      "\n",
      "[Donald Trump] Réponse: Ladies and gentlemen, let me tell you, my economic policies are not just about big corporations or Wall Street. They're about the backbone of our nation - small businesses! You know, the mom-and-pop shops, the local cafes, the family-owned stores that make our communities unique and vibrant.\n",
      "\n",
      "Firstly, I'm going to cut through the red tape. We'll simplify regulations so that small businesses can focus on what they do best - creating jobs and serving their customers. No more endless forms or confusing rules. We'll make it easier for them to start, grow, and thrive.\n",
      "\n",
      "Secondly, I'm going to lower taxes. Not just for the wealthy, but for everyone. Small businesses will see a significant reduction in their tax burden, freeing up more money to invest in their businesses, hire more employees, and expand. We'll also provide tax incentives for businesses that create new jobs or invest in their communities.\n",
      "\n",
      "Thirdly, I'm going to invest in infrastructure. Our roads, bridges, and broadband networks are crumbling. Small businesses need reliable infrastructure to operate efficiently. By investing in infrastructure, we'll create jobs and make it easier for small businesses to reach new markets.\n",
      "\n",
      "Lastly, I'm going to support small business owners. We'll provide mentorship programs, access to capital, and resources to help them succeed. We'll also create a small business-friendly environment that encourages innovation and entrepreneurship.\n",
      "\n",
      "So, when you vote for me, you're not just voting for a candidate. You're voting for a future where small businesses can flourish, creating jobs and prosperity for all. Together, we can make America great again!\n",
      "\n",
      "id='0063d096ca724f8ca86a5cce6ca98bc3' object='chat.completion' model='ministral-8b-latest' usage=UsageInfo(prompt_tokens=613, completion_tokens=36, total_tokens=649) created=1737746291 choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='{\\n  \"confidence\": 0.95,\\n  \"aggressiveness\": 0.75,\\n  \"enthusiasm\": 0.85\\n}', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
      "[LOG] Émotions mises à jour de Donald Trump: {'confidence': 0.95, 'aggressiveness': 0.75, 'enthusiasm': 0.85}\n",
      "\n",
      "[Kamala Harris] Réponse: Thank you for asking that question. I'm glad you're interested in understanding how my economic policies will support small businesses. My approach is twofold: fostering a supportive environment and providing targeted assistance.\n",
      "\n",
      "Firstly, I propose a reduction in regulatory burdens. Small businesses often struggle with excessive red tape, which can hinder their growth and innovation. By simplifying regulations and streamlining processes, we can help small businesses operate more efficiently and focus on what they do best—creating jobs and driving local economies.\n",
      "\n",
      "Secondly, I plan to invest in infrastructure and education. A robust infrastructure network is crucial for small businesses to reach new markets and customers. By investing in roads, broadband, and other essential infrastructure, we can lower the costs of doing business and make it easier for small businesses to thrive.\n",
      "\n",
      "Additionally, I will prioritize education and workforce development. A skilled workforce is vital for small businesses to compete and grow. By investing in vocational training and education programs, we can ensure that small businesses have access to the talent they need to succeed.\n",
      "\n",
      "Lastly, I propose targeted financial assistance programs. Small businesses often face challenges in accessing capital. By providing grants, low-interest loans, and other financial support, we can help small businesses start, expand, and innovate.\n",
      "\n",
      "In summary, my policies aim to create a supportive environment for small businesses by reducing regulatory burdens, investing in infrastructure and education, and providing targeted financial assistance. These measures will not only help small businesses grow but also contribute to sustainable economic growth and job creation.\n",
      "\n",
      "id='1b830e9e1e0c46b3805ead25ea7fc408' object='chat.completion' model='ministral-8b-latest' usage=UsageInfo(prompt_tokens=581, completion_tokens=55, total_tokens=636) created=1737746299 choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='{\\n  \"confidence\": 0.9,\\n  \"determination\": 0.95,\\n  \"calmness\": 0.85,\\n  \"empathy\": 0.7,\\n  \"engagement\": 0.8\\n}', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
      "[LOG] Émotions mises à jour de Kamala Harris: {'confidence': 0.9, 'determination': 0.95, 'calmness': 0.85, 'empathy': 0.7, 'engagement': 0.8}\n",
      "\n",
      "\n",
      "==================================================\n",
      "Tour de débat n°2\n",
      "==================================================\n",
      "\n",
      "[MODERATOR] Question: What is your plan to reduce unemployment?\n",
      "\n",
      "[Donald Trump] Réponse: **Plan to Reduce Unemployment:**\n",
      "\n",
      "Ladies and gentlemen, let me tell you, my plan to reduce unemployment is straightforward and effective. We're going to put America back to work, and we're going to do it by focusing on job creation, workforce development, and supporting our workers.\n",
      "\n",
      "Firstly, we're going to cut taxes for businesses and individuals. Lower taxes mean more money in your pocket and more capital for businesses to invest in growth and hiring. We'll also eliminate unnecessary regulations that stifle job growth.\n",
      "\n",
      "Secondly, we're going to invest in our workforce. We'll provide vocational training and education programs to ensure that Americans have the skills they need to fill the jobs of the future. We'll also create apprenticeship programs that pair workers with employers, giving them on-the-job training and a clear path to a successful career.\n",
      "\n",
      "Thirdly, we're going to support our workers. We'll provide a strong safety net, including unemployment benefits and job retraining programs, to help those who are temporarily out of work. We'll also ensure that our workers have access to affordable healthcare and childcare, so they can focus on their careers and provide for their families.\n",
      "\n",
      "Lastly, we're going to create a business-friendly environment that encourages job growth. We'll cut red tape, lower taxes, and invest in infrastructure to make it easier for businesses to operate and expand. We'll also support small businesses, which are the backbone of our economy and create the majority of new jobs.\n",
      "\n",
      "Together, these policies will create a strong, vibrant economy that puts Americans back to work and ensures that everyone has the opportunity to succeed. We can make America great again, and we can do it by putting our people first. Thank you, and God bless America!\n",
      "\n",
      "id='55c45dad7ecc4852a296e30b29bf4f86' object='chat.completion' model='ministral-8b-latest' usage=UsageInfo(prompt_tokens=1004, completion_tokens=34, total_tokens=1038) created=1737746305 choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='{\\n  \"confidence\": 0.98,\\n  \"aggressiveness\": 0.8,\\n  \"enthusiasm\": 0.9\\n}', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n",
      "[LOG] Émotions mises à jour de Donald Trump: {'confidence': 0.98, 'aggressiveness': 0.8, 'enthusiasm': 0.9}\n",
      "\n"
     ]
    },
    {
     "ename": "SDKError",
     "evalue": "API error occurred: Status 429\n{\"message\":\"Requests rate limit exceeded\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 307\u001b[0m\n\u001b[1;32m    304\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Pause pour simuler un timing\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Harris répond\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m harris_response \u001b[38;5;241m=\u001b[39m \u001b[43mharris_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrespond\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopponent_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mharris_agent\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Réponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mharris_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 154\u001b[0m, in \u001b[0;36mAIAgent.respond\u001b[0;34m(self, input_text, opponent_state)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mGénère une réponse basée sur le contexte fourni.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m:return: Réponse de l'IA\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation_history\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_text})\n\u001b[0;32m--> 154\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopponent_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopponent_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN/A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    158\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation_history\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname: response})\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "Cell \u001b[0;32mIn[6], line 200\u001b[0m, in \u001b[0;36mAIAgent._generate_response\u001b[0;34m(self, instructions, opponent_state, environment_description, max_tokens)\u001b[0m\n\u001b[1;32m    177\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    178\u001b[0m     {\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m     },\n\u001b[1;32m    196\u001b[0m ]\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Hypothetical call to LLM API\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/Documents/hackaton_mistral/.venv/lib/python3.13/site-packages/mistralai/chat.py:153\u001b[0m, in \u001b[0;36mChat.complete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, stream, stop, random_seed, response_format, tools, tool_choice, presence_penalty, frequency_penalty, n, prediction, safe_prompt, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    152\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mSDKError(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m, http_res\u001b[38;5;241m.\u001b[39mstatus_code, http_res_text, http_res\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    157\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n",
      "\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 429\n{\"message\":\"Requests rate limit exceeded\"}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from mistralai import Mistral\n",
    "\n",
    "MISTRAL_KEY = \"MaFKaY7R8TYrOLd56ZDRBcUfatOrebRh\"\n",
    "\n",
    "MODEL = \"ministral-8b-latest\"\n",
    "\n",
    "def link_with_newline_middle(strings):\n",
    "    if len(strings) <= 1:\n",
    "        return ''.join(strings)  # Return as is for single or empty lists\n",
    "    middle = len(strings) // 2\n",
    "    # Join the first part, add '\\n', and then join the rest\n",
    "    return '\\n'.join([' '.join(strings[:middle]), ' '.join(strings[middle:])])\n",
    "\n",
    "class LLMArbitraryAgent:\n",
    "    \"\"\"\n",
    "    This class uses an LLM to update emotions by analyzing the entire context:\n",
    "    - Character traits\n",
    "    - Current/initial emotions\n",
    "    - General conversation context\n",
    "    - Conversation history\n",
    "\n",
    "    The LLM is prompted to return new emotion values in JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model=MODEL):\n",
    "        self.model = model\n",
    "\n",
    "    def update_emotions(\n",
    "        self, \n",
    "        character, \n",
    "        current_emotions, \n",
    "        general_context, \n",
    "        conversation_history\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calls an LLM to analyze the agent's overall context\n",
    "        and produce updated emotion values in JSON format.\n",
    "\n",
    "        :param character: dict describing the AI's personality traits\n",
    "        :param current_emotions: dict of current emotion levels\n",
    "        :param general_context: dict describing the debate/topic context\n",
    "        :param conversation_history: list of message dicts representing the conversation so far\n",
    "        :return: dict of updated emotions (floats in [0.0, 1.0])\n",
    "        \"\"\"\n",
    "\n",
    "        # Prepare the prompt for the LLM\n",
    "        system_prompt = (\n",
    "            \"You are an emotion update engine. \"\n",
    "            \"Given the AI's character traits, current emotions, general context, and conversation history, \"\n",
    "            \"you will propose updated emotion values. The output must be strictly valid JSON, \"\n",
    "            \"with keys as emotion names and values as floats between 0.0 and 1.0.\\n\"\n",
    "        )\n",
    "\n",
    "        user_prompt = f\"\"\"Character: {character}\n",
    "Current Emotions: {current_emotions}\n",
    "General Context: {general_context}\n",
    "Conversation History: {conversation_history}\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the above information.\n",
    "2. Propose new emotion values in valid JSON format, for example:\n",
    "   {{\n",
    "     \"confidence\": 0.9,\n",
    "     \"aggressiveness\": 0.7,\n",
    "     \"enthusiasm\": 0.8\n",
    "   }}\n",
    "Make sure each emotion is within [0.0, 1.0].\n",
    "\"\"\"\n",
    "\n",
    "        # Prepare messages for the chat completion API\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "\n",
    "        # ------------------------------\n",
    "        # Hypothetical call to LLM API\n",
    "        # ------------------------------\n",
    "        chat_response = client.chat.complete(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={\"type\":\"json_object\"},\n",
    "            max_tokens=200  # Ajustez si nécessaire\n",
    "        )\n",
    "\n",
    "        print(chat_response)\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        # Extract LLM's raw text response (which should be JSON)\n",
    "        llm_output_text = chat_response.choices[0].message.content.strip()\n",
    "        # Remove any ```json or ``` markers\n",
    "        cleaned_response = re.sub(r\"```(json)?\", \"\", llm_output_text).strip()\n",
    "\n",
    "        # Parse JSON\n",
    "        try:\n",
    "            updated_emotions = json.loads(cleaned_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: LLM response could not be parsed as JSON. Response: {cleaned_response}\")\n",
    "            updated_emotions = current_emotions  # fallback\n",
    "\n",
    "        # Clamp to [0.0, 1.0]\n",
    "        final_emotions = {}\n",
    "        for emotion, val in updated_emotions.items():\n",
    "            if isinstance(val, (int, float)):\n",
    "                clamped_val = max(0.0, min(1.0, float(val)))\n",
    "                final_emotions[emotion] = clamped_val\n",
    "            else:\n",
    "                final_emotions[emotion] = current_emotions.get(emotion, 0.5)\n",
    "\n",
    "        return final_emotions\n",
    "\n",
    "\n",
    "class AIAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        character,\n",
    "        emotions,\n",
    "        goal,\n",
    "        general_context,\n",
    "        arbitrary_agent=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialise l'agent IA avec ses attributs de base.\n",
    "\n",
    "        :param name: Nom de l'agent\n",
    "        :param character: dict décrivant la personnalité de l'IA\n",
    "        :param emotions: dict des émotions actuelles de l'IA\n",
    "        :param goal: Objectif principal de l'IA\n",
    "        :param general_context: Contexte général (ex: sujet du débat)\n",
    "        :param arbitrary_agent: Objet gérant la logique de mise à jour des émotions\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.character = character\n",
    "        self.emotions = emotions\n",
    "        self.goal = goal\n",
    "        self.general_context = general_context\n",
    "        self.arbitrary_agent = arbitrary_agent\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def respond(self, input_text, opponent_state):\n",
    "        \"\"\"\n",
    "        Génère une réponse basée sur le contexte fourni.\n",
    "\n",
    "        :param input_text: Texte reçu\n",
    "        :param opponent_state: État actuel de l'adversaire (dict)\n",
    "        :return: Réponse de l'IA\n",
    "        \"\"\"\n",
    "        self.conversation_history.append({\"user\": input_text})\n",
    "        \n",
    "        response = self._generate_response(\n",
    "            instructions=input_text,\n",
    "            opponent_state=opponent_state,\n",
    "            environment_description=\"N/A\"\n",
    "        )\n",
    "        self.conversation_history.append({self.name: response})\n",
    "        return response\n",
    "\n",
    "    def update_emotions(self):\n",
    "        \"\"\"\n",
    "        Met à jour les émotions en fonction d'une analyse via l'arbitrary_agent (LLM).\n",
    "        \"\"\"\n",
    "        if self.arbitrary_agent is not None:\n",
    "            self.emotions = self.arbitrary_agent.update_emotions(\n",
    "                character=self.character,\n",
    "                current_emotions=self.emotions,\n",
    "                general_context=self.general_context,\n",
    "                conversation_history=self.conversation_history\n",
    "            )\n",
    "        else:\n",
    "            print(\"No arbitrary agent provided. Emotions remain unchanged.\")\n",
    "\n",
    "    def _generate_response(self, instructions, opponent_state, environment_description, max_tokens=None):\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    f\"General context: {self.general_context}\\n\"\n",
    "                    f\"Character: {self.character}\\n\"\n",
    "                    f\"Goal: {self.goal}\\n\"\n",
    "                    f\"Emotions: {self.emotions}\\n\"\n",
    "                    f\"Environment: {environment_description}\\n\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"Instructions: {instructions}\\n\"\n",
    "                    f\"Opponent state: {opponent_state}\\n\"\n",
    "                    f\"Conversation history: {self.conversation_history}\"\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "        # ------------------------------\n",
    "        # Hypothetical call to LLM API\n",
    "        # ------------------------------\n",
    "        chat_response = client.chat.complete(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens if max_tokens else None,\n",
    "            \n",
    "        )\n",
    "        # ------------------------------------------------\n",
    "        return chat_response.choices[0].message.content\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Configuration générale du contexte et des agents\n",
    "# ------------------------------------------------\n",
    "\n",
    "general_context = {\n",
    "    \"topic\": \"Economic Policy\",\n",
    "    \"setting\": \"Televised national debate\",\n",
    "    \"audience\": \"Undecided voters seeking clarity on candidates' economic plans\"\n",
    "}\n",
    "\n",
    "# Donald Trump\n",
    "trump_character = {\n",
    "    \"dominant\": True,\n",
    "    \"charismatic\": True,\n",
    "    \"unpredictable\": True,\n",
    "    \"assertive\": True,\n",
    "    \"narcissistic\": True\n",
    "}\n",
    "trump_emotions = {\n",
    "    \"confidence\": 0.9,\n",
    "    \"aggressiveness\": 0.8,\n",
    "    \"enthusiasm\": 0.7\n",
    "}\n",
    "trump_goal = \"Persuade the audience that his economic policies will lead to national prosperity and job growth.\"\n",
    "\n",
    "# Kamala Harris\n",
    "harris_character = {\n",
    "    \"analytical\": True,\n",
    "    \"empathetic\": True,\n",
    "    \"methodical\": True,\n",
    "    \"decisive\": True,\n",
    "    \"direct\": True\n",
    "}\n",
    "harris_emotions = {\n",
    "    \"confidence\": 0.85,\n",
    "    \"determination\": 0.9,\n",
    "    \"calmness\": 0.8\n",
    "}\n",
    "harris_goal = \"Convince the audience that her economic plans offer sustainable growth and address income inequality.\"\n",
    "\n",
    "# Agent pour la mise à jour des émotions via LLM\n",
    "llm_arbitrary_agent = LLMArbitraryAgent(model=MODEL)\n",
    "\n",
    "# Création des deux agents\n",
    "trump_agent = AIAgent(\n",
    "    name=\"Donald Trump\",\n",
    "    character=trump_character,\n",
    "    emotions=trump_emotions,\n",
    "    goal=trump_goal,\n",
    "    general_context=general_context,\n",
    "    arbitrary_agent=llm_arbitrary_agent\n",
    ")\n",
    "\n",
    "harris_agent = AIAgent(\n",
    "    name=\"Kamala Harris\",\n",
    "    character=harris_character,\n",
    "    emotions=harris_emotions,\n",
    "    goal=harris_goal,\n",
    "    general_context=general_context,\n",
    "    arbitrary_agent=llm_arbitrary_agent\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the Mistral client\n",
    "client = Mistral(api_key=MISTRAL_KEY)\n",
    "# ---------------------------------------\n",
    "# Boucle pour générer le dialogue\n",
    "# ---------------------------------------\n",
    "# Exemples de questions (vous pouvez en ajouter ou utiliser des inputs directs)\n",
    "questions = [\n",
    "    \"How will your policies affect small businesses?\",\n",
    "    \"What is your plan to reduce unemployment?\",\n",
    "    \"How do you intend to tackle national debt?\",\n",
    "]\n",
    "\n",
    "NUMBER_OF_TURNS = 3  # Nombre de tours de dialogue\n",
    "\n",
    "for turn in range(NUMBER_OF_TURNS):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Tour de débat n°{turn+1}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Sélection d'une question (simplement en rotation ici)\n",
    "    question = questions[turn % len(questions)]\n",
    "    print(f\"[MODERATOR] Question: {question}\\n\")\n",
    "\n",
    "    # Trump répond\n",
    "    trump_response = trump_agent.respond(input_text=question, opponent_state={})\n",
    "    print(f\"[{trump_agent.name}] Réponse: {trump_response}\\n\")\n",
    "    time.sleep(1) \n",
    "\n",
    "    # Mise à jour des émotions de Trump\n",
    "    trump_agent.update_emotions()\n",
    "    print(f\"[LOG] Émotions mises à jour de {trump_agent.name}: {trump_agent.emotions}\\n\")\n",
    "    time.sleep(1)  # Pause pour simuler un timing\n",
    "\n",
    "    # Harris répond\n",
    "    harris_response = harris_agent.respond(input_text=question, opponent_state={})\n",
    "    print(f\"[{harris_agent.name}] Réponse: {harris_response}\\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Mise à jour des émotions de Harris\n",
    "    harris_agent.update_emotions()\n",
    "    print(f\"[LOG] Émotions mises à jour de {harris_agent.name}: {harris_agent.emotions}\\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "# Fin de la boucle de débat\n",
    "print(\"=== Fin du débat ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladies and Gentlemen, thank you for having me here today. I stand before you not just as a candidate, but as a visionary who believes in the power of our nation's potential. We are at a crossroads, and I am here to tell you that my economic policies are the key to unlocking a future of prosperity and job growth for every American.\n"
     ]
    }
   ],
   "source": [
    "print(trump_agent._generate_response(\"first person to take the parole, have a concise response\", \"waiting\", \"people in the crowd are waiting\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
